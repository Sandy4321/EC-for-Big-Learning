{"name":"EC for Big Learning","tagline":"Join us in fusing our EC classifiers","body":"# Big Data Learning\r\n\r\nHave you ever wanted to run your EC algorithm in the cloud? Discouraged by the complexity of EC2? We will deploy your EC algorithm on the cloud for you with our FCUBE framework!\r\n\r\nFCUBE supports a Bring Your Own Learner (BYOL) model: it deploys your EC algorithm to hundreds of machines and does all the data management for you. No scripts, no launch hassles, no tedious result collection. FCUBE is (EC) deployment as a service:\r\n\r\n![FCUBE](images/f3.png)\r\n\r\nFor this competition, our goal is to unite the developers of interesting EC classifier algorithms to solve relevant problems of public domain. We seek an experienced informed discussion on the various approaches and techniques without being distracted by one problem at hand. Therefore, we have set up the following format:\r\n\r\n* Everyone gets the same computational budget in Amazon EC2\r\n* Everyone works on the same datasets\r\n* Organizers select the features\r\n* You contribute a classifier learning algorithm with your own fitness function, operators and search logic\r\n* You contribute a classifier learning algorithm which accepts training data in csv format and references a Java properties file which you provide (details below), and outputs a classifier.\r\n* You contribute a classifier learning algorithm in executable format (Java, python) or as source code (must be compilable in Linux: C, C++ etc)\r\n* You contribute a piece of code which applies your classifier to test data and produces labels.\r\n* FCUBE executes your algorithm with the competition training data\r\n* FCUBE retrieves the solutions from the cloud nodes, computes the testing predictions, and returns them to you.\r\n* FCUBE also filters and fuses the predictions using different methods. Everyone receives their fused results and everyone contributes to a collaborative fused solution among all contributors.\r\n\r\n# Instructions for competitors.\r\n\r\nThe competition will be divided in three phases:\r\n\r\n## Phase 1: Bring Your Own Learner\r\nIn a first step, you will adapt your learner to be compliant with FCUBE's interface; we provide an example with <a href=\"gpfunction.jar\" target=\"_blank\">GPFunction</a>, one of our Java learners for numerical features, together with a <a href=\"higgs_noheader_02.csv\" target=\"_blank\">split of the higgs dataset</a> that you can use to debug yours:\r\n\r\n###Learner Training interface\r\n\r\n![Predict Interface](images/learnerbbtrain.png)\r\n\r\n####Inputs:\r\n1. a path to a CSV file: we support csv files with and without headers. When headers are included, the first line of the file contains the name and type of the features (integer, float, or nominal). Check this dummy dataset <a href=\"dummy_headers.csv\" target=\"_blank\">with headers</a> and <a href=\"dummy_noheaders.csv\" target=\"_blank\">without headers</a> and this split of the Higgs dataset <a href=\"higgs_header_02.csv\" target=\"_blank\">with headers</a> and <a href=\"higgs_noheader_02.csv\" target=\"_blank\">without headers</a>.\r\n2. learning time deadline\r\n3. Properties File with Java syntax for your extra parameters. Check this <a href=\"parameters.properties\" target=\"_blank\">example</a>.\r\n\r\n####Outputs:\r\n1. a model stored in a single file on disk\r\n\r\nExample with our <a href=\"gpfunction.jar\" target=\"_blank\">GPFunction</a> learner:\r\n<pre><code>$ java -jar gpfunction.jar -train higgs_noheader_02.csv -minutes 10 -properties params.properties\r\n</code></pre>\r\n\r\n###Learner Predict interface\r\n\r\n![Predict Interface](images/learnerbbpredict.png)\r\n\r\n####Inputs:\r\n1. path to a CSV file\r\n2. path to where the model is stored\r\n3. path to where the predictions will be stored\r\n\r\n####Outputs:\r\n1. predictions in CSV file (one label per line)\r\n\r\nExample: the GPFunction learner produces several models. Let is pick the model called mostAccurate.txt and generate predictions for the same split higgs_noheader_02.csv.\r\n<pre><code>$ java -jar gpfunction.jar -predict higgs_noheader_02.csv -model mostAccurate.txt -o predictions.csv\r\n</code></pre> \r\nThe executable gpfunction.jar will generate a csv file named predictions.csv containing one label per line.\r\n\r\n## Phase 2: Choose the deployment strategy:\r\n\r\nOnce we have the final number of participants, each participant will be assigned a budget in Amazon EC2. Then, each participant will be asked to choose a combination of:\r\n\r\n1. EC2 flavor, i.e the virtual machine specs (check EC2 Instance Type Details [here](https://aws.amazon.com/ec2/instance-types/))\r\n2. running time per instance\r\n3. number of instances\r\n4. data-parallel strategy (% of data and % of variables/features sampled per instance)\r\n\r\nIn the last step prior to deployment, participants will have the option to expose a range of possible choices for their learner-specific parameters. This way, it will possible to assign different parameters to the different instances running on the cloud. More details to come on this aspect.\r\n\r\nFinally, we will deploy your learners in EC2. We will analyze the predictions of your learner and communicate performance metrics.\r\n\r\n# The datasets:\r\n\r\nIn this edition of the workshop, we will target binary classification problems. For each dataset, we will release samples of different sizes. These samples will allow to estimate the running time of the classifier learning algorithms given the size of the data.\r\n\r\n## Higgs dataset: \r\n\r\nThe Higgs dataset is a public dataset. It is composed of 11000000 exemplars and 28 real-valued features. Expect a CSV file with any number of features where the last column is the label (0 or 1).\r\n\r\nPlease remain connected for updates on the datasets.\r\n\r\n# Support or Contact\r\nHaving with the adaptation of your learner? Feel free to contact us by email at [iarnaldo@mit.edu](mailto:iarnaldo@mit.edu) and weâ€™ll try to help you sort it out.\r\n\r\n# Authors and Contributors\r\nThis competition is organized by the [Any-Scale Learning For All (ALFA)](http://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/) group at MIT.\r\n![ALFA](images/ALFA-logo-lousy.png)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}