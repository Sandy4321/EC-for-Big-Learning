<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>EC for Big Learning by flexgp</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>EC for Big Learning</h1>
        <p>Join us in fusing our EC classifiers</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/flexgp/EC-for-Big-Learning" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/flexgp/EC-for-Big-Learning/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/flexgp/EC-for-Big-Learning/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1>
<a name="big-data-learning" class="anchor" href="#big-data-learning"><span class="octicon octicon-link"></span></a>Big Data Learning</h1>

<p>Have you ever wanted to run your EC algorithm in the cloud? Discouraged by the complexity of EC2? We will deploy your EC algorithm on the cloud for you with our FCUBE framework!</p>

<p>FCUBE supports a Bring Your Own Learner (BYOL) model: it deploys your EC algorithm to hundreds of machines and does all the data management for you. No scripts, no launch hassles, no tedious result collection. FCUBE is (EC) deployment as a service:</p>

<p><img src="images/f3.png" alt="FCUBE"></p>

<p>For this competition, our goal is to unite the developers of interesting EC classifier algorithms to solve publicly available problems. We seek an experienced informed discussion on the various approaches and techniques without being distracted by one problem at hand. Therefore, we have set up the following format:</p>

<ul>
<li>Everyone gets the same computational budget in Amazon EC2</li>
<li>Everyone works on the same datasets</li>
<li>Organizers select the features</li>
<li>You contribute a classifier learning algorithm with your own fitness function, operators and search logic</li>
<li>You contribute a classifier learning algorithm which accepts training data in csv format and references a Java properties file which you provide (details below), and outputs a classifier.</li>
<li>You contribute a classifier learning algorithm in executable format (Java, python) or as source code (must be compilable in Linux: C, C++ etc)</li>
<li>You contribute a piece of code which applies your classifier to test data and produces labels.</li>
<li>FCUBE executes your algorithm with the competition training data</li>
<li>FCUBE retrieves the solutions from the cloud nodes, computes the testing predictions, and returns them to you.</li>
<li>FCUBE also filters and fuses the predictions using different methods. Everyone receives their fused results and everyone contributes to a collaborative fused solution among all contributors.</li>
</ul><h1>
<a name="instructions-for-competitors" class="anchor" href="#instructions-for-competitors"><span class="octicon octicon-link"></span></a>Instructions for competitors.</h1>

<p>The competition will be divided in three phases:</p>

<h2>
<a name="phase-1-bring-your-own-learner" class="anchor" href="#phase-1-bring-your-own-learner"><span class="octicon octicon-link"></span></a>Phase 1: Bring Your Own Learner</h2>

<p>In a first step, you will adapt your learner to be compliant with FCUBE's interface; we provide an example with one of our learners together with a dataset you can use to debug yours:</p>

<h3>
<a name="learner-training-interface" class="anchor" href="#learner-training-interface"><span class="octicon octicon-link"></span></a>Learner Training interface</h3>

<p><img src="images/learnerbbtrain.png" alt="Predict Interface"></p>

<h4>
<a name="inputs" class="anchor" href="#inputs"><span class="octicon octicon-link"></span></a>Inputs:</h4>

<ol>
<li>a path to a CSV file: we support csv files with and without headers. Check this dummy dataset with headers and without and this split of the Higgs dataset with headers and without.</li>
<li>learning time deadline</li>
<li>Properties File with Java syntax for your extra parameters. Check this example.</li>
</ol><h4>
<a name="outputs" class="anchor" href="#outputs"><span class="octicon octicon-link"></span></a>Outputs:</h4>

<ol>
<li>a model stored in a single file on disk</li>
</ol><p>Example with our GPFunction learner:</p>

<pre><code>$ java -jar gpfunction.jar -train split_02.csv -minutes 10 -properties params.properties
</code></pre>

<h3>
<a name="learner-predict-interface" class="anchor" href="#learner-predict-interface"><span class="octicon octicon-link"></span></a>Learner Predict interface</h3>

<p><img src="images/learnerbbpredict.png" alt="Predict Interface"></p>

<h4>
<a name="inputs-1" class="anchor" href="#inputs-1"><span class="octicon octicon-link"></span></a>Inputs:</h4>

<ol>
<li>path to a CSV file</li>
<li>path to where the model is stored</li>
<li>path to where the predictions will be stored</li>
</ol><h4>
<a name="outputs-1" class="anchor" href="#outputs-1"><span class="octicon octicon-link"></span></a>Outputs:</h4>

<ol>
<li>predictions in CSV file (one label per line)</li>
</ol><p>Example: the GPFunction learner produces several models. Let is pick the model called mostAccurate.txt and generate predictions for the same split split_02.csv.</p>

<pre><code>$ java -jar gpfunction.jar -predict split_02.csv -model mostAccurate.txt -o predictions.csv
</code></pre> 

<p>The executable gpfunction.jar will generate a csv file named predictions.csv containing one label per line.</p>

<h3>
<a name="the-data-format" class="anchor" href="#the-data-format"><span class="octicon octicon-link"></span></a>The data format</h3>

<p>In this edition of the workshop, we will target binary classification problems. Algorithms submitted to the competition must read data in CSV format where the last column contains the label (0 or 1). For ease of use, we support two csv formats:</p>

<ol>
<li>csv without header line</li>
<li>csv with a header line: the first line of the file contains the name and type of the features (integer, float, or nominal). </li>
</ol><p>Please find below an example of data file with header composed of 5 features plus the label. In the example variable X1 is integer. X2 and X3 are floats. Finally X4 are X5 are nominal variables.</p>

<pre><code>$ head -n 5 example.csv
i_X1,f_X2,f_X3,n_X4,n_X5,label
2,0.7879572,1.0466304,blue,c,0.0
6,0.58576685,0.20243178,yellow,b,0.0
18,0.7604114,0.8667035,green,a,1.0
25,0.7485672,1.3335116,blue,b,1.0
</code></pre>

<h2>
<a name="phase-2-choose-the-deployment-strategy" class="anchor" href="#phase-2-choose-the-deployment-strategy"><span class="octicon octicon-link"></span></a>Phase 2: Choose the deployment strategy:</h2>

<p>Once we have the final number of participants, each participant will be assigned a budget in Amazon EC2. Then, each participant will be asked to choose a combination of:</p>

<ol>
<li>EC2 flavor, i.e the virtual machine specs (check EC2 Instance Type Details <a href="https://aws.amazon.com/ec2/instance-types/">here</a>)</li>
<li>running time per instance</li>
<li>number of instances</li>
</ol><p>Participants will also need to decide a set of parameters concerning the data-parallel strategy:</p>

<ol>
<li>% of data sampled per instance</li>
<li>% of variables/features sampled per instance </li>
</ol><p>In the last step prior to deployment, participants will have the option to expose a range of possible choices for their learner-specific parameters. This way, it will possible to assign different parameters to the different instances running on the cloud. More details to come on this aspect.</p>

<h2>
<a name="phase-3-deployment-of-the-learners-and-communication-of-the-results" class="anchor" href="#phase-3-deployment-of-the-learners-and-communication-of-the-results"><span class="octicon octicon-link"></span></a>Phase 3: Deployment of the learners and communication of the results</h2>

<p>In the last phase we will deploy your learners in EC2. We will analyze the predictions of your learner and communicate performance metrics.</p>

<h1>
<a name="the-datasets" class="anchor" href="#the-datasets"><span class="octicon octicon-link"></span></a>The datasets:</h1>

<p>For each dataset, we will release samples of different sizes. These samples will allow to estimate the running time of the classifier learning algorithms given the size of the data.</p>

<h3>
<a name="higgs-dataset" class="anchor" href="#higgs-dataset"><span class="octicon octicon-link"></span></a>Higgs dataset:</h3>

<p>Please remain connected for the updates on the datasets used for the competition.</p>

<h1>
<a name="example-of-learner-gpfunction" class="anchor" href="#example-of-learner-gpfunction"><span class="octicon octicon-link"></span></a>Example of learner: GPFunction</h1>

<p>In this section we provide an example of a learner integrated in FCUBE, namely our GPFunction classifier  learning algorithm based on Genetic Programming. Please download the GPFunction from <a href="https://github.com/flexgp/EC-for-Big-Learning/releases">here</a>.</p>

<p>We use the split higgs_02.csv released to prepare the competition to demonstrate the interfaces of the GPFunction classifier. The Higgs dataset is composed of 28 features and a binary label 0 or 1. Note that in this case the 28 features are floats. You will realize that the released split contains only 5 features. Since FCUBE will automatically sample exemplars and features for you, your learner should be able to work with any number of features (so avoid hard-coded values!).</p>

<h3>
<a name="step-0-optional-prepare-a-properties-file-in-java-syntax" class="anchor" href="#step-0-optional-prepare-a-properties-file-in-java-syntax"><span class="octicon octicon-link"></span></a>Step 0 (optional): prepare a properties file in Java syntax</h3>

<p>First we prepare a properties file in Java syntax for the parameters specific to GP Function classifier:</p>

<pre><code>$ nano params.properties
xover_op=operator.SinglePointKozaCrossover
external_threads=4
false_negative_weight=0.5
pop_size=500
</code></pre>

<h3>
<a name="step-2-execute-the-classifier-learning-algorithm" class="anchor" href="#step-2-execute-the-classifier-learning-algorithm"><span class="octicon octicon-link"></span></a>Step 2: execute the classifier learning algorithm</h3>

<p>The GPFunction learner is executed given a csv file, a time deadline, and a properties file in Java Syntax. In the example below, the GPFunction classifier is invoked with a time deadline of 10 minutes and the properties file shown above.</p>

<pre><code>$ java -jar gpfunction.jar -train split_02.csv -minutes 10 -properties params.properties
</code></pre>

<h3>
<a name="step-3-obtain-the-predictions" class="anchor" href="#step-3-obtain-the-predictions"><span class="octicon octicon-link"></span></a>Step 3: obtain the predictions</h3>

<p>The GPFunction learner produces several models. Let is pick the model called mostAccurate.txt and generate predictions for the same split split_02.csv.</p>

<pre><code>$ java -jar gpfunction.jar -predict split_02.csv -model mostAccurate.txt -o predictions.csv
</code></pre> 

<p>The executable gpfunction.jar will generate a csv file named predictions.csv containing one label per line.</p>

<h3>
<a name="support-or-contact" class="anchor" href="#support-or-contact"><span class="octicon octicon-link"></span></a>Support or Contact</h3>

<p>Having with the adaptation of your learner? Feel free to contact us by email at <a href="mailto:iarnaldo@mit.edu">iarnaldo@mit.edu</a> and we’ll try to help you sort it out.</p>

<h3>
<a name="authors-and-contributors" class="anchor" href="#authors-and-contributors"><span class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>This competition is organized by the <a href="http://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/">Any-Scale Learning For All (ALFA)</a> group at MIT.
<img src="images/ALFA-logo-lousy.png" alt="ALFA"></p>
      </section>
      <footer>
        <p>Project maintained by <a href="https://github.com/flexgp">flexgp</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>